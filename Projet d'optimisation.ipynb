{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet d'optimisation \n",
    "## Par  Rania Fathi et Pierre Sion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- Modélisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 :\n",
    "On définit l'élasticité-prix comme étant la variation relative de la quantité demandée par rapport au prix, soit encore: \n",
    "    $\\varepsilon_i = \\frac{\\frac{dx_i}{x_i}}{\\frac{dp_i}{p_i}} $ \n",
    "où l'on a noté $x_i$ la demande et $p_i$ le prix du ième produit \n",
    "    \n",
    "Cela peut encore s'écrire: \n",
    "$\\varepsilon_i = \\frac{\\partial x_i}{\\partial p_i} \\frac{p_i}{x_i}$\n",
    "\n",
    "Comme on s'attend à ce que la demande pour un produit diminue si le prix augmente, on a $\\varepsilon_i \\leq 0$\n",
    "\n",
    "Pour ce qui est de l'élasticité prix croisée entre le gouda et l'edam, elle vaut: \n",
    "\n",
    "$\\varepsilon_c = \\frac{\\frac{dx_g}{x_g}}{\\frac{dp_e}{p_e}} = \\frac{\\partial x_g}{\\partial p_e} \\frac{p_e}{x_g}$\n",
    "\n",
    "Les biens considérés étant substituables, on a $\\varepsilon_c \\geq 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 :\n",
    "Le lait brut possède une quantité de matière grasse totale répartie entre les quatre produits, que l'on note $M$. En notant $m_i$ la teneur en matière grasse présente dans chaque produit, on a : \n",
    "\n",
    "$ \\sum_{i=1}^{4}m_i x_i \\leq M$\n",
    "\n",
    "On fait par ailleurs le choix de mettre une inégalité plutôt qu'une égalité pour considérer le cas où tout le lait n'est pas transformé "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 : \n",
    "De la même manière, on note $L$ la quantité totale de lactose contenue dans le lait, et $l_i$ celle contenue dans chaque produit, et on a alors la contrainte suivante: \n",
    "\n",
    "$\\sum_{i=1}^{4} l_i x_i \\leq L $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 :\n",
    "\n",
    "Afin de garantir la paix sociale, la moyenne (pondérée par la part de chaque produit dans le budget) des changements de prix relatifs ne doit pas être positive.\n",
    "On note $b_i$ la part du ième produit dans le budget (déterminée à partir des données de l'année N-1). Cette contrainte s'écrit donc: \n",
    "$\\sum_{i=1}^{4}b_i \\frac{dp_i}{p_i} \\leq 0$\n",
    "\n",
    "Comme les contraintes dont on dispose jusque maintenant portent sur les quantités et non pas les prix, on la réécrit sous la forme suivante : $ \\sum_{i=1}^4 \\frac{b_i}{\\epsilon_i} \\frac{dx_i}{x_i} \\leq 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 :\n",
    "\n",
    "_En supposant qu'on dispose déjà des $(p_i)_{1\\leq i\\leq4}$, $(b_i)_{1\\leq i\\leq4}$, $(\\epsilon_i)_{1\\leq i\\leq4}$, $(m_i)_{1\\leq i \\leq 4}$, de $M$ et $L$_  \n",
    "On dispose donc du problème d'optimisation sous contraintes suivant : $\\max_{c(x) \\leq 0} \\Pi (x)$ \n",
    "\n",
    "où le profit $\\Pi:\\mathbf{R}^4 \\rightarrow \\mathbf{R}  $ vaut $\\Pi(x) = \\sum_{i=1}^4 p_i x_i $ (En toute rigueur, $\\Pi$ est égal au revenu plutôt qu'au profit, mais l'omission du terme $-C$ correspondant au coût total du lait acheté ne modifie pas le problème d'optimisation à résoudre).\n",
    "\n",
    "Et les contraintes $c : \\mathbf{R}^4 \\rightarrow \\mathbf{R}^7$ sont les suivantes : \n",
    "\n",
    "$c_1(x) = - x_1 \\\\ \n",
    "c_2(x) = - x_2\\\\ \n",
    "c_3(x) = - x_3\\\\ \n",
    "c_4(x) = - x_4$\n",
    "\n",
    "Ces quatre premières contraintes traduisent le fait que les quantités considérées sont nécessairement positives. Et nous disposons des deux contraintes des questions 2 et 3: \n",
    "\n",
    "$c_5(x) = \\sum_{i=1}^{4}m_i x_i - M\\\\ \n",
    "c_6(x) = \\sum_{i=1}^{4} l_i x_i - L $\n",
    "\n",
    "Et enfin :\n",
    "$c_7(x) =  \\sum_{i=1}^4 \\frac{b_i}{\\epsilon_i} \\frac{dx_i}{x_i} \\leq 0$\n",
    "\n",
    "NB: Il aurait été possible d'ajouter les contraintes portant sur le signe de l'élasticité des produits, imposant que l'augmentation du prix d'un produit réduit la demande, ou encore celles stipulant que les prix des produits se doivent d'être positifs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche donc à résoudre $max_{C^Tp-d \\leq 0} b^T p - \\frac{1}{2} p^T A p$ soit encore $min_{C^Tp-d \\leq 0} \\frac{1}{2} p^T A p- b^T p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II- Implémentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cadre de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import optimize\n",
    " #Données :\n",
    "A = np.array([[3.0825,0,0,0],\n",
    "              [0,0.0405,0,0],\n",
    "              [0,0,0.0271,-0.0031],\n",
    "              [0,0,-0.0031,0.0054]])\n",
    "b = np.array([2671,135,103,19])\n",
    "\n",
    "C = np.array([[-0.0401,-0.0162,-0.0039,0.0002],\n",
    "              [-0.1326,-0.0004,-0.0034,0.0006],\n",
    "              [1.5413,0,0,0],\n",
    "              [0,0.0203,0,0],\n",
    "              [0,0,0.0136,-0.0015],\n",
    "              [0,0,-0.0016,0.0027],\n",
    "              [0.0160,0.0004,0.0005,0.0002]])\n",
    "\n",
    "d = np.array([-92.6,-29,2671,135,103,19,10])\n",
    "\n",
    "x0=np.array([2055,54,63,17])\n",
    "lambda0 = np.array([1e-2 for i in range(7)])\n",
    "\n",
    "#Fonction à minimiser :\n",
    "def f(x):\n",
    "    return 0.5 * np.vdot(np.dot(x,A),x) - np.vdot(b,x)\n",
    "\n",
    "def grad_f(x):\n",
    "    return np.dot(A,x) - b \n",
    "\n",
    "# Contraintes:\n",
    "\n",
    "def c(x) :\n",
    "    return np.dot(C,x) - d \n",
    "\n",
    "def grad_c(x):\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par déterminer la solution de notre problème à l'aide de scipy, afin de pouvoir y comparer nos résultats: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: -214311.83304309193\n",
      "            Iterations: 9\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 5\n",
      "x_scipy_f :  [1732.95269029 1362.3463871   376.88087187 2156.24872887]\n",
      "c(x_scipy_f) :  [-5.93232130e-09 -2.01322111e+02 -1.84613455e-05 -1.07344368e+02\n",
      " -1.01108793e+02 -1.37811378e+01  1.88918718e+01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ineq_cons_f = {'type': 'ineq','fun' : c,'jac' : grad_c}\n",
    "res_scipy_f = optimize.minimize(f, x0, method='SLSQP', jac = grad_f, constraints=[ineq_cons_f], options={'ftol': 1e-9, 'disp': True})\n",
    "print(\"x_scipy_f : \", res_scipy_f.x)\n",
    "print(\"c(x_scipy_f) : \", c(res_scipy_f.x))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Méthode d'Uzawa, à pas fixe et variable (wolfe): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uzawa_fixed_step_array(fun, grad_fun, c, grad_c, x0, l, rho, lambda0, max_iter = 100000, epsilon_grad_L = 1e-8):\n",
    "\tk = 0\n",
    "\txk = x0\n",
    "\tlambdak = lambda0\n",
    "\tgrad_Lagrangienk_xk = grad_fun(xk) + np.dot(lambdak,grad_c(xk))\n",
    "\twhile ((k<max_iter) and (np.linalg.norm(grad_Lagrangienk_xk)>epsilon_grad_L)):\n",
    "\t\tgrad_Lagrangienk_xk = grad_fun(xk) + np.dot(lambdak,grad_c(xk))\n",
    "\t\tpk = -grad_Lagrangienk_xk\n",
    "\t\txk = xk + l*pk;    \n",
    "\t\tlambdak= np.maximum(0, lambdak + rho*c(xk))\t\n",
    "\t\tk = k + 1\n",
    "\tprint(\"Nombre d'iterations : \", k)\n",
    "\tprint(\"lambdak : \", lambdak)\n",
    "\treturn xk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage(): \n",
    "    print(\"Uzawa fixed step V...\")\n",
    "    x_fixed_step_V = uzawa_fixed_step_array(f, grad_f, c, grad_c, x0, 0.0001, 0.1, lambda0)\n",
    "    print(x_fixed_step_V) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wolfe_step(fun, grad_fun, xk, pk, c1 = 0.25, c2 = 0.75, M = 1000):\n",
    "\tl_moins = 0\n",
    "\tl_plus = 0\n",
    "\tf_xk = fun(xk)\n",
    "\tgrad_f_xk = grad_fun(xk)\n",
    "\tli = 0.0001\n",
    "\ti = 0\n",
    "\twhile(i < M):\n",
    "\t\tif (fun(xk+li*pk)>(f_xk+c1*li*np.dot(grad_f_xk,pk))):\n",
    "\t\t\tl_plus = li\n",
    "\t\t\tli = (l_moins+l_plus)/2.0\n",
    "\t\telse:\n",
    "\t\t\tif (np.dot(grad_fun(xk+li*pk),pk) < c2*np.dot(grad_f_xk,pk)):\n",
    "\t\t\t\tl_moins = li\n",
    "\t\t\t\tif (l_plus == 0):\n",
    "\t\t\t\t\tli = 2*li\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tli = (l_moins+l_plus)/2.0\n",
    "\t\t\telse:\n",
    "\t\t\t\t#print(\"Nb itérations : \", i)\n",
    "\t\t\t\treturn li\n",
    "\t\ti = i + 1\n",
    "\t#print(\"Trop d'itérations de Wolfe\")\n",
    "\treturn li\n",
    "\n",
    "def uzawa_wolfe_step_array(fun, grad_fun, c, grad_c, x0, rho, lambda0, max_iter = 100000, epsilon_grad_L = 1e-8):\n",
    "\tk = 0\n",
    "\txk = x0\n",
    "\tlambdak = lambda0\n",
    "\tgrad_Lagrangienk_xk = grad_fun(xk) + np.dot(lambdak,grad_c(xk))\n",
    "\twhile ((k<max_iter) and (np.linalg.norm(grad_Lagrangienk_xk)>epsilon_grad_L)):\n",
    "\t\tLagrangienk = lambda x : fun(x) + np.dot(lambdak, c(x))\n",
    "\t\tgrad_Lagrangienk = lambda x : grad_fun(x) + np.dot(lambdak, grad_c(x))\n",
    "\t\tgrad_Lagrangienk_xk = grad_Lagrangienk(xk)\n",
    "\t\tpk = -grad_Lagrangienk_xk\n",
    "\t\tlk = wolfe_step(Lagrangienk, grad_Lagrangienk, xk, pk)\n",
    "\t\txk = xk + lk*pk;    \n",
    "\t\tlambdak = np.maximum(0, lambdak + rho*c(xk))\n",
    "\t\tk = k + 1\n",
    "\tprint(\"Nombre d'iterations : \", k)\n",
    "\tprint(\"lambdak_array : \", lambdak)\n",
    "\treturn xk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uzawa with gradient descent and Wolfe step do not converge (it is because of the initial step in wolfe_step() function. The choice 1 as initial step is good for Quasi-Newton or Newton methods, not for gradient descent. If you take li = 0.0001 instead of 1, the method will converge. You will see the convergence is similar to the gradient descent with fixed step.)\n",
    "def affichage_wolfe():\n",
    "    print(\"Uzawa wolfe step V...\")\n",
    "    x_wolfe_step_V = uzawa_wolfe_step_array(f, grad_f, c, grad_c, x0, 0.1, lambda0)\n",
    "    print(\"x_wolfe_step_V : \", x_wolfe_step_V)\n",
    "    print(\"g(x_wolfe_step_V) : \", c(x_wolfe_step_V))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Méthode de Newton BFGS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_BFGS_array(f, grad_f, c, grad_c, x0, lambda0, max_iter = 100000, epsilon_grad_L = 1e-5):\n",
    "\tk = 0\n",
    "\txk = x0\n",
    "\tlambdak = lambda0\n",
    "\tHk = np.identity(len(x0))\n",
    "\tgrad_Lagrangienk_xk = grad_f(xk) + np.dot(lambdak,grad_c(xk))\n",
    "\twhile ((k<max_iter) and (np.linalg.norm(grad_Lagrangienk_xk)>epsilon_grad_L)):\n",
    "\t\tLagrangienk = lambda x : f(x) + np.dot(lambdak, c(x))\n",
    "\t\tgrad_Lagrangienk = lambda x : grad_f(x) + np.dot(lambdak, grad_c(x))\n",
    "\t\tgrad_Lagrangienk_xk = grad_Lagrangienk(xk)\n",
    "\t\tpk = -np.matmul(Hk,grad_Lagrangienk_xk)\n",
    "\t\tlk = wolfe_step(Lagrangienk, grad_Lagrangienk, xk, pk)\n",
    "\t\txk1 = xk + lk*pk\n",
    "\t\tgrad_Lagrangienk_xk1 = grad_Lagrangienk(xk1)\n",
    "\t\tsk = xk1 - xk\n",
    "\t\tyk = grad_Lagrangienk_xk1 - grad_Lagrangienk_xk\n",
    "\t\tgammak = 1.0/np.dot(yk, sk)\n",
    "\t\tAk = np.identity(len(x0)) - gammak*np.multiply(sk[:, np.newaxis], yk)\n",
    "\t\tBk = np.identity(len(x0)) - gammak*np.multiply(yk[:, np.newaxis], sk)\n",
    "\t\tHk = np.matmul(np.matmul(Ak, Hk), Bk) + gammak*np.multiply(sk[:, np.newaxis], sk)\n",
    "\t\txk = xk1 \n",
    "\t\t\n",
    "\t\tfor i in range(len(c(xk))):\n",
    "\t\t\trhok = np.dot(grad_c(xk)[i], np.matmul(Hk,grad_c(xk)[i]))\n",
    "\t\t\tlambdak[i] = np.maximum(0, lambdak[i] + (1/rhok)*c(xk)[i])\n",
    "\t\tk = k + 1\n",
    "\tprint(\"Nombre d'iterations : \", k)\n",
    "\tprint(\"lambdak : \", lambdak)\n",
    "\treturn xk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage_BFGS():\n",
    "    print(\"Newton BFGS V...\")\n",
    "    x_newton_BFGS_f = newton_BFGS_array(f, grad_f, c, grad_c, x0, lambda0)\n",
    "    print(\"x_newton_BFGS_V : \", x_newton_BFGS_f)\n",
    "    print(\"g(x_newton_BFGS_V) : \", c(x_newton_BFGS_f))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première méthode : Algorithme de Arrow-Hurwickz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par construire le projecteur sur $\\mathbb{R}_{+}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(x):\n",
    "    for i in range(0,len(x)):\n",
    "        if x[i]<0:\n",
    "            x[i]=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui permet d'implémenter l'algorithme AH : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_ah(x0,lambda0,epsilon=0.01,mu=10**-5,alpha=0.001, max_iterations = 10000, epsilon_frad_f = 1e-8):   \n",
    "    lambdak=lambda0\n",
    "    xl = x0\n",
    "    xk = xl - epsilon*(grad_f(xl) + np.dot(C,lambdak))\n",
    "    compteur = 1 \n",
    "    while(compteur <= max_iterations and np.linalg.norm(grad_f(pk))>epsilon_grad_f):\n",
    "        compteur += 1\n",
    "        xk = xk - epsilon * (b - np.dot(A,pk) + (np.transpose(C)).dot(lambdak))\n",
    "        lambdak = proj(lambdak + alpha * (np.dot(C,pk) - d))\n",
    "        print(pk)\n",
    "    return pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (7,4) and (7,) not aligned: 4 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-575638dd73a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo_ah\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-369e0d68c63f>\u001b[0m in \u001b[0;36malgo_ah\u001b[1;34m(x0, lambda0, epsilon, mu, alpha, max_iterations, epsilon_frad_f)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlambdak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlambda0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mxl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mxk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambdak\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mcompteur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompteur\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmax_iterations\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mepsilon_grad_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (7,4) and (7,) not aligned: 4 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "print(algo_ah(x0, lambda0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3663.5375, -132.813 , -101.3454,  -19.1035])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_f(P0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
